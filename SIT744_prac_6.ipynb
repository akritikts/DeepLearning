{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SIT744_prac_6.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0PWKlbt6_dm",
        "colab_type": "text"
      },
      "source": [
        "# SIT744 Practical 6: Introducing ConvNet\n",
        "\n",
        "*Dr Wei Luo*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JEtYNgr7JuP",
        "colab_type": "text"
      },
      "source": [
        "<div class=\"alert alert-info\">\n",
        "We suggest that you run this notebook using Google Colab.\n",
        "</div>\n",
        "\n",
        "## Learning objectives\n",
        "\n",
        "- Construct and train a Convolutional Neural Network\n",
        "- Regularise training with data augmentation and dropout\n",
        "\n",
        "## Pre-practical readings\n",
        "\n",
        "- [Introduction to convnets](https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/5.1-introduction-to-convnets.ipynb)\n",
        "- [Using convnets with small datasets](https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/5.2-using-convnets-with-small-datasets.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INRcSjg97dCJ",
        "colab_type": "text"
      },
      "source": [
        "## Task 1 Training a convnet\n",
        "\n",
        "We will use the cats vs. dogs dataset in the textbook to show how to build a ConvNet to classify cat vs dog photos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X81y3EvD9-Aw",
        "colab_type": "text"
      },
      "source": [
        "### Task 1.1 Prepare dataset\n",
        "\n",
        " As the dataset is available in `tfds`, we will get it from there."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlLCYfGZ_i6b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "TRAIN_DS_SIZE = 2000\n",
        "VALID_DS_SIZE = 1000\n",
        "TEST_DS_SIZE = 1000\n",
        "\n",
        "(cat_dog_train, cat_dog_valid, cat_dog_test), info = tfds.load('cats_vs_dogs', \n",
        "                                                               split=[f'train[:{TRAIN_DS_SIZE}]', \n",
        "                                                                      f'train[{TRAIN_DS_SIZE}:{TRAIN_DS_SIZE + VALID_DS_SIZE}]', \n",
        "                                                                      f'train[{TRAIN_DS_SIZE + VALID_DS_SIZE}:{TRAIN_DS_SIZE + VALID_DS_SIZE + TEST_DS_SIZE}]'],\n",
        "                                                               with_info=True,\n",
        "                                                               as_supervised=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WV77d0OQ64Nd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "info"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQN0QqR0I_Dd",
        "colab_type": "text"
      },
      "source": [
        "You can display some images using the function from the last practical."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tOtKCxlIJQt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Show the image and label\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def show(image, label):\n",
        "  plt.figure()\n",
        "  plt.imshow(image)\n",
        "  plt.title(label)\n",
        "  plt.axis('off')\n",
        "\n",
        "for image, label in cat_dog_valid.take(5):\n",
        "  show(image, label.numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hek-1ejQECQM",
        "colab_type": "text"
      },
      "source": [
        "**exercise** \n",
        "\n",
        "1. Are the images of equal size? What is the value range of each pixel?\n",
        "2. What happens if you change the argument `as_supervised` to `False`?\n",
        "3. Check if the two classes are balanced in the data splits."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSTNLegtNGOe",
        "colab_type": "text"
      },
      "source": [
        "Last week, we saw how to use `map` function to preprocess images. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVNcPrpEHoKY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMAGE_SIZE = 150\n",
        "def pre_process_image(image, label):\n",
        "  image = tf.image.convert_image_dtype(image, tf.float32) ## Instead of manually scale the image, call a `tf.image` tool\n",
        "  image = tf.image.resize(image, (IMAGE_SIZE, IMAGE_SIZE))\n",
        "  return image, label\n",
        "\n",
        "TRAIN_BATCH_SIZE = 20\n",
        "train_batches = cat_dog_train.map(pre_process_image).batch(TRAIN_BATCH_SIZE).cache().repeat()\n",
        "validation_batches = cat_dog_valid.map(pre_process_image).batch(TRAIN_BATCH_SIZE).cache().repeat()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPfBKF3_Hs5C",
        "colab_type": "text"
      },
      "source": [
        "**question** Why do we add `repeat()` at the end of the pipelines?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyRMd48UHG9y",
        "colab_type": "text"
      },
      "source": [
        "### Task 1.2 Build a convnet\n",
        "\n",
        "We follow the common practice of using multiple blocks of Conv2D+MaxPooling2D layers. The number of channels was increased from 32 to 128, to form the visual features. \n",
        "In the end, two dense layers were used to perform the classification based on the convolutional features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHVzGYJAHPHM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "\n",
        "\n",
        "def make_model():\n",
        "  model = models.Sequential()\n",
        "  model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
        "                          input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3)))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(512, activation='relu'))\n",
        "  model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "  model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
        "              metrics=['acc'])\n",
        "\n",
        "  return model\n",
        "\n",
        "model = make_model()  \n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cntHBAso18j",
        "colab_type": "text"
      },
      "source": [
        "Now we can feed the input pipelines to the model's `fit` method.\n",
        "As we used `repeat()` in the pipelines, we need to define what an **epoch** means. This is done through the `steps_per_epoch` argument."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "105zc15Adher",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "\n",
        "model = make_model()  \n",
        "\n",
        "history = model.fit(\n",
        "      train_batches,\n",
        "      steps_per_epoch=100,\n",
        "      epochs=30,\n",
        "      validation_data=validation_batches,\n",
        "      validation_steps=50\n",
        "      )\n",
        "\n",
        "model.save('cats_and_dogs_small_1.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtydiNZdppvF",
        "colab_type": "text"
      },
      "source": [
        "We will use a nicer-looking plot function to view the training curves."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYjZowju915x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%pip install git+https://github.com/tensorflow/docs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISpno10G9i6I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow_docs as tfdocs\n",
        "import tensorflow_docs.plots\n",
        "\n",
        "plotter = tfdocs.plots.HistoryPlotter()\n",
        "plotter.plot({\"\": history}, metric = \"acc\")\n",
        "plt.title(\"Accuracy\")\n",
        "plt.ylim([0,1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPkRsFDLqPtp",
        "colab_type": "text"
      },
      "source": [
        "Overfitting is more obvious from the plot of loss functions. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxCEn4QPp_00",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plotter = tfdocs.plots.HistoryPlotter()\n",
        "plotter.plot({\"\": history}, metric = \"loss\")\n",
        "plt.title(\"Accuracy\")\n",
        "plt.ylim([0,1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yw8wkY1QqMyO",
        "colab_type": "text"
      },
      "source": [
        "Let's look at how the model performs on the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19MoVvATxEVs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.evaluate(cat_dog_test.map(pre_process_image).batch(TRAIN_BATCH_SIZE))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyfDX_47x2ha",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for images, labels in cat_dog_test.map(pre_process_image).batch(TRAIN_BATCH_SIZE).take(1):\n",
        "  predictions = model.predict(images) \n",
        "  for image, prediction in zip(images, predictions):\n",
        "    show(image, np.round(prediction))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OiE_zXPZjPHe",
        "colab_type": "text"
      },
      "source": [
        "**exercise** We used 3x3 convolution filters in the above example. Try increase the size of the convolution filters (particular at the first convolution layer) and see how the training and testing accuracy change. You may change the `strides` argument for larger filters. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTmShoWQBN_S",
        "colab_type": "text"
      },
      "source": [
        "## Task 2 Regularise the training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BP0lNaZi4dT",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "### Task 2.1 Using data augmentation\n",
        "\n",
        "In Week 5, we learned that two ways to address overfitting include data augmentation and regularisation. In training convnet, data augmentation often means generating randomly transformed images from the existing training set. We can use image transformations provided in `tf.image`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yIb40QIRXeWX",
        "colab": {}
      },
      "source": [
        "for images, labels in cat_dog_train.take(1):\n",
        "  show(image, label.numpy())\n",
        "\n",
        "  show(tf.image.flip_left_right(image), label=\"Flip the image left to right\") \n",
        "\n",
        "  show(tf.image.rot90(image), \"Rotate an image by 90 degrees\")\n",
        "\n",
        "  show(tf.squeeze(tf.image.rgb_to_grayscale(image)), \"Grayscale the image\")\n",
        "\n",
        "  show(tf.image.adjust_saturation(image, 3), \"Saturate an image\")\n",
        "\n",
        "  show(tf.image.adjust_brightness(image, 0.4), \"Change the brightness\")\n",
        "\n",
        "  show(tf.image.central_crop(image, central_fraction=0.5), \"Center crop the image\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEzrbr9fX55w",
        "colab_type": "text"
      },
      "source": [
        "**exercise** Follow the example above to \n",
        "\n",
        "- flip the image upside down\n",
        "- change the image with random brightness\n",
        "- change the image with random contrast\n",
        "- randomly crop the image\n",
        "\n",
        "\n",
        "Now let's add random transformations to the input pipeline."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRG0-SYEdaSA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "def augment(image,label):\n",
        "  image = tf.image.convert_image_dtype(image, tf.float32) \n",
        "  image = tf.image.random_flip_left_right(image)\n",
        "  image = tf.image.resize(image, (IMAGE_SIZE, IMAGE_SIZE))\n",
        "  image = tf.image.resize_with_pad(image, IMAGE_SIZE + 6, IMAGE_SIZE + 6) # Add pixels of padding\n",
        "  image = tf.image.random_crop(image, size=[IMAGE_SIZE, IMAGE_SIZE, 3]) # Random crop back to IMAGE_SIZExIMAGE_SIZE\n",
        "  return image, label\n",
        "\n",
        "augmented_train_batches = (\n",
        "    cat_dog_train\n",
        "    .cache()\n",
        "    # The augmentation is added here.\n",
        "    .map(augment, num_parallel_calls=AUTOTUNE)\n",
        "    .batch(TRAIN_BATCH_SIZE)\n",
        "    .repeat()\n",
        "    .prefetch(AUTOTUNE)\n",
        ")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1qacnMr7LLZ",
        "colab_type": "text"
      },
      "source": [
        "Retrain the model with the augmented data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ewx9UP0XXcmJ",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "\n",
        "model = make_model()\n",
        "\n",
        "aug_history = model.fit(\n",
        "      augmented_train_batches,\n",
        "      steps_per_epoch=100,\n",
        "      epochs=30,\n",
        "      validation_data=validation_batches,\n",
        "      validation_steps=100\n",
        "      )\n",
        "\n",
        "model.save('cats_and_dogs_small_augmented.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "973gTb97w12b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plotter = tfdocs.plots.HistoryPlotter()\n",
        "plotter.plot({ \"Augmented\": aug_history, \"Non-Augmented\": history}, metric = \"acc\")\n",
        "plt.title(\"Accuracy\")\n",
        "plt.ylim([0,1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiDh8LLEBCqy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plotter = tfdocs.plots.HistoryPlotter()\n",
        "plotter.plot({ \"Augmented\": aug_history, \"Non-Augmented\": history}, metric = \"loss\")\n",
        "plt.title(\"Loss\")\n",
        "plt.ylim([0,1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQGNZt6nt0KP",
        "colab_type": "text"
      },
      "source": [
        "As we can see, the augmented data reduced overfitting.\n",
        "\n",
        "\n",
        "**exercise** Change the example above to incorporate the following types of augmentations:\n",
        "\n",
        "- Randomly flip an image vertically (upside down)\n",
        "- Randomly rotate an image\n",
        "- Randomly adjust the brightness, hue, saturation, or contrast"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6MOsj2u_AkR",
        "colab_type": "text"
      },
      "source": [
        "### Task 2.2 Add dropout\n",
        "\n",
        "In week 4, we introduced dropout as a regularisation measure. It is often applied between dense layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dyjv-sneatY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  model = models.Sequential()\n",
        "  model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
        "                          input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3)))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dropout(0.2))\n",
        "  model.add(layers.Dense(512, activation='relu'))\n",
        "  model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "  model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
        "              metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uA-E2Zfc76rV",
        "colab_type": "text"
      },
      "source": [
        "Retrain with both data augmentation and dropout."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xav3Wrl2ejiE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dropout_history = model.fit(\n",
        "      augmented_train_batches,\n",
        "      steps_per_epoch=100,\n",
        "      epochs=30,\n",
        "      validation_data=validation_batches,\n",
        "      validation_steps=100\n",
        "      )\n",
        "\n",
        "model.save('cats_and_dogs_small_augmented.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBIXvxIdAep8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plotter = tfdocs.plots.HistoryPlotter()\n",
        "plotter.plot({\"Augmented\": aug_history, \"Non-Augmented\": history, \"Dropout\": dropout_history}, metric = \"acc\")\n",
        "plt.title(\"Accuracy\")\n",
        "plt.ylim([0,1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fo6-ZzJ_q0NA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plotter = tfdocs.plots.HistoryPlotter()\n",
        "plotter.plot({ \"Augmented\": aug_history, \"Non-Augmented\": history, \"Dropout\": dropout_history}, metric = \"loss\")\n",
        "plt.title(\"Loss\")\n",
        "plt.ylim([0,1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLVVUewrrgHN",
        "colab_type": "text"
      },
      "source": [
        "As you can see that overfitting has been further reduced.\n",
        "\n",
        "**exercise** Try different dropout rates and see how they impact on the training and validation accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Z05uqCFGl6r",
        "colab_type": "text"
      },
      "source": [
        "## Additional resources\n",
        "\n",
        "- TensorFlow tutorial on [image classification](https://www.tensorflow.org/tutorials/images/classification)\n",
        "- TensorFlow tutorial on [data augmentation](https://www.tensorflow.org/tutorials/images/data_augmentation)"
      ]
    }
  ]
}